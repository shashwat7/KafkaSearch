# These buffer sizes seem to be needed to avoid consumer switching to
# a mode where it processes one bufferful every 5 seconds with multiple
# timeouts along the way.  No idea why this happens.
fetch.min.bytes=50000
receive.buffer.bytes=262144
max.partition.fetch.bytes=2097152


enable.auto.commit=true


## Application Properties ##
# For writing Kafka Stream
save.complete.message = false
number.of.consumers = 3
key.regex=.
regex.extract.groups=false
write.to=file
file.path=
# For reading from Kafka Stream
search.from=file
results.path=PATH_TO_FILE_WHERE_YOU_WANT_TO_SAVE_YOUR_RESULTS


## Kafka Properties ##
kafka.topic=kafka.topic
bootstrap.servers=localhost:9092
group.id=KafkaSearch
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
session.timeout.ms=20000

